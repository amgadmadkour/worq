{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Specify input paths\n",
    "\n",
    "#WatDiv\n",
    "# s2rdf_fl = open(\"/home/amadkour/relatedsys/S2RDF_v1.1-spark2.1/QueryTranslator/WatDivQuerySet/RESULTS-WORKLOAD-test1-5K/resultTimes.txt\")\n",
    "# worq_file_adaptive = open(\"/home/amadkour/projects/worq/test/output/dbout-1B/results-worq-1B-adaptive.txt\")\n",
    "# results_dir = \"results_watdiv\"\n",
    "\n",
    "#LUBM\n",
    "s2rdf_fl = open(\"/home/amadkour/relatedsys/S2RDF_v1.1-spark2.1/QueryTranslator/WatDivQuerySet/RESULTS-WORKLOAD-lubm-1K/resultTimes-1-2.txt\")\n",
    "worq_file_adaptive = open(\"/home/amadkour/projects/worq/test/output/dbout-lubm/results-worq-1K-reduced.txt\")\n",
    "results_dir = \"results_lubm-1K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "####### S2RDF ############\n",
    "time_s2rdf = list()\n",
    "results_s2rdf = dict()\n",
    "all_s2rdf_results = list()\n",
    "\n",
    "for line in s2rdf_fl:\n",
    "    line = line.strip()\n",
    "    parts = line.split('\\t')\n",
    "    id = int(parts[0])\n",
    "    parts[0] = id\n",
    "    time = float(parts[1].split(\" [SO-OS-SS-VP__\")[0])\n",
    "    parts[1] = time\n",
    "    time_s2rdf.append(time)\n",
    "    all_s2rdf_results.append(parts)\n",
    "    results_s2rdf[id] = time\n",
    "    \n",
    "    \n",
    "######## WORQ-ADAPTIVE #############\n",
    "time_worq_adaptive = list()\n",
    "results_worq_adaptive = dict()\n",
    "all_worq_results_adaptive = list()\n",
    "\n",
    "for line in worq_file_adaptive:\n",
    "    line = line.strip()\n",
    "    parts = line.split('\\t')\n",
    "    id = int(parts[0].split(\"__VP_SO-OS-SS-VP\")[0])\n",
    "    pattern_id = (((id - 1) / 100) + 1)\n",
    "    parts[0] = id\n",
    "    time = float(parts[2])\n",
    "    parts[2] = time\n",
    "    all_worq_results_adaptive.append(parts)\n",
    "    time_worq_adaptive.append(time)\n",
    "    results_worq_adaptive[id] = time\n",
    "    \n",
    "    \n",
    "results_s2rdf = collections.OrderedDict(sorted(results_s2rdf.items()))\n",
    "results_worq_adaptive = collections.OrderedDict(sorted(results_worq_adaptive.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workload Query Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "    \n",
    "time_s2rdf.sort(reverse=True)\n",
    "#time_worq.sort(reverse=True)\n",
    "time_worq_adaptive.sort(reverse=True)\n",
    "\n",
    "query_execution_out = open(\"/home/amadkour/projects/worq/\"+results_dir+\"/queryexecution-sorted.csv\",\"w\")\n",
    "\n",
    "query_execution_out.write(\"CARD\\tS2RDF\\n\")\n",
    "for a,b in zip(time_worq_adaptive,time_s2rdf):\n",
    "    query_execution_out.write(str(a) +\"\\t\"+ str(b)+\"\\n\")\n",
    "    \n",
    "query_execution_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Patterns mean execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def meanExecutionTime(entries):    \n",
    "    id_dict = dict()\n",
    "    mean_time_dict = dict()\n",
    "    for key,value in entries.iteritems():\n",
    "        id = int(key)\n",
    "        pattern_id = (((id - 1) / 100) + 1)\n",
    "        time = float(value)\n",
    "        if pattern_id in id_dict:\n",
    "            lst = id_dict[pattern_id]\n",
    "            lst.append(time)\n",
    "            id_dict[pattern_id] = lst\n",
    "        else:\n",
    "            lst = list()\n",
    "            lst.append(time)\n",
    "            id_dict[pattern_id] = lst\n",
    "\n",
    "    for key in id_dict.keys():\n",
    "        lst = id_dict[key]\n",
    "        meantime = 0\n",
    "        size = len(lst)\n",
    "        for elem in lst:\n",
    "            meantime += elem\n",
    "        mean_time_dict[key] = meantime / size\n",
    "\n",
    "    result = dict()\n",
    "    for key in mean_time_dict.keys():\n",
    "        result[key] = mean_time_dict[key]\n",
    "    \n",
    "    return collections.OrderedDict(sorted(result.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern Mean Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mean_worq = meanExecutionTime(results_worq)\n",
    "mean_worq_adaptive = meanExecutionTime(results_worq_adaptive)\n",
    "mean_s2rdf = meanExecutionTime(results_s2rdf)\n",
    "\n",
    "mean_pqe = open(\"/home/amadkour/projects/worq/\"+results_dir+\"/mean-patternexecution.csv\",\"w\")\n",
    "\n",
    "mean_pqe.write(\"CARD\\tS2RDF\\n\")\n",
    "for a,b in zip(mean_worq_adaptive, mean_s2rdf):\n",
    "    mean_pqe.write(str(mean_worq_adaptive[a]) +\"\\t\" +str(mean_s2rdf[b])+\"\\n\")\n",
    "\n",
    "mean_pqe.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern Mean Query Execution Time (SORTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_pqe_sorted = open(\"/home/amadkour/projects/worq/\"+results_dir+\"/mean-patternexecution-sorted.csv\",\"w\")\n",
    "\n",
    "# #WORQ\n",
    "# mean_times_worq = list()\n",
    "# for key,val in mean_worq.iteritems():\n",
    "#     mean_times_worq.append(float(val))\n",
    "# mean_times_worq.sort()\n",
    "\n",
    "#WORQ-ADAPTIVE\n",
    "mean_times_worq_adaptive = list()\n",
    "for key,val in mean_worq_adaptive.iteritems():\n",
    "    mean_times_worq_adaptive.append(float(val))\n",
    "mean_times_worq_adaptive.sort()\n",
    "\n",
    "#S2RDF\n",
    "mean_times_s2rdf = list()\n",
    "for key,val in mean_s2rdf.iteritems():\n",
    "    mean_times_s2rdf.append(float(val))\n",
    "mean_times_s2rdf.sort()\n",
    "\n",
    "mean_pqe_sorted.write(\"CARD\\tS2RDF\\n\")\n",
    "for a,b in zip(mean_times_worq_adaptive,mean_times_s2rdf):\n",
    "    mean_pqe_sorted.write(str(a)+\"\\t\"+str(b)+\"\\n\")\n",
    "\n",
    "mean_pqe_sorted.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify number of triples versus mean execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### WORQ-ADAPTIVE #######\n",
    "numtriples_exectime_adaptive = dict()\n",
    "for entry in all_worq_results_adaptive:\n",
    "    numtriples = entry[7]\n",
    "    if numtriples in numtriples_exectime_adaptive:\n",
    "        lst = numtriples_exectime_adaptive[numtriples]\n",
    "        time = float(entry[2])\n",
    "        lst.append(time)\n",
    "        numtriples_exectime_adaptive[numtriples] = lst\n",
    "    else:\n",
    "        lst = list()\n",
    "        time = float(entry[2])\n",
    "        lst.append(time)\n",
    "        numtriples_exectime_adaptive[numtriples] = lst\n",
    "\n",
    "# Calculate the average for every pattern\n",
    "numtriples_worq_results_adaptive = dict()\n",
    "for key,val in numtriples_exectime_adaptive.iteritems():\n",
    "    size = len(val)\n",
    "    total = 0.0\n",
    "    for v in val:\n",
    "        total += v\n",
    "    avg = total/size\n",
    "    numtriples_worq_results_adaptive[int(key)] = float(avg)\n",
    "ordered_numtriples_worq_adaptive = collections.OrderedDict(sorted(numtriples_worq_results_adaptive.items()))\n",
    "\n",
    "#### S2RDF - Get the number of triples for S2RDF from WORQ\n",
    "id_numtriples_map = dict()\n",
    "for val in all_worq_results_adaptive:\n",
    "    id_numtriples_map[val[0]] = val[7]\n",
    "    \n",
    "numtriples_id_map_s2rdf = dict()\n",
    "numtriples_exectime = dict()\n",
    "for entry in all_s2rdf_results:\n",
    "    numtriples = id_numtriples_map[entry[0]]\n",
    "    if numtriples in numtriples_exectime:\n",
    "        lst = numtriples_exectime[numtriples]\n",
    "        time = float(entry[1])\n",
    "        lst.append(time)\n",
    "        numtriples_exectime[numtriples] = lst\n",
    "    else:\n",
    "        lst = list()\n",
    "        time = float(entry[1])\n",
    "        lst.append(time)\n",
    "        numtriples_exectime[numtriples] = lst\n",
    "\n",
    "#Calculate the average for every pattern\n",
    "numtriples_results = dict()\n",
    "for key,val in numtriples_exectime.iteritems():\n",
    "    size = len(val)\n",
    "    total = 0.0\n",
    "    for v in val:\n",
    "        total += v\n",
    "    avg = total/size\n",
    "    numtriples_results[int(key)] = float(avg)\n",
    "    \n",
    "ordered_numtriples_s2rdf = collections.OrderedDict(sorted(numtriples_results.items()))\n",
    "\n",
    "### Save Results\n",
    "\n",
    "numtriples_out = open(\"/home/amadkour/projects/worq/\"+results_dir+\"/mean-numtriples.csv\",\"w\")\n",
    "numtriples_out.write(\"NumTriples\\tCARD\\tS2RDF\\n\")\n",
    "for a,b in zip(ordered_numtriples_worq_adaptive,ordered_numtriples_s2rdf):\n",
    "    numtriples_out.write(str(a)+\"\\t\"+str(ordered_numtriples_worq_adaptive[a])+ \"\\t\" + str(ordered_numtriples_s2rdf[b])+\"\\n\")\n",
    "numtriples_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Identify the queries that ran on cold cache in our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cold_ids = list()\n",
    "for entry in all_worq_results_adaptive:\n",
    "    parts = entry\n",
    "    if parts[6] == \"false\":\n",
    "        cold_ids.append(parts[0])\n",
    "        count += 1\n",
    "\n",
    "print count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the corresponding queries from S2RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "s2rdf_cold_matches = list()\n",
    "for entry in all_s2rdf_results:\n",
    "    if entry[0] in cold_ids:\n",
    "        s2rdf_cold_matches.append(entry[1])\n",
    "\n",
    "print len(s2rdf_cold_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the cold queries to files for both systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WORQ-ADAPTIVE\n",
    "list_worq_cold_ids_adaptive = list()\n",
    "for entry in all_worq_results_adaptive:\n",
    "    id = entry[0]\n",
    "    if id in cold_ids:\n",
    "        list_worq_cold_ids_adaptive.append(float(entry[2]))\n",
    "        \n",
    "list_worq_cold_ids_adaptive.sort(reverse=True)\n",
    "\n",
    "\n",
    "#S2RDF\n",
    "list_s2rdf_cold_ids = list()\n",
    "for entry in all_s2rdf_results:\n",
    "    id = entry[0]\n",
    "    if id in cold_ids:\n",
    "        list_s2rdf_cold_ids.append(float(entry[1]))\n",
    "        \n",
    "list_s2rdf_cold_ids.sort(reverse=True)\n",
    "\n",
    "cold_out = open(\"/home/amadkour/projects/worq/\"+results_dir+\"/cold.csv\",\"w\")\n",
    "cold_out.write(\"CARD\\tS2RDF\\n\")\n",
    "for a,b in zip(list_worq_cold_ids_adaptive,list_s2rdf_cold_ids):\n",
    "    cold_out.write(str(a)+\"\\t\"+str(b)+\"\\n\")\n",
    "cold_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare number of joins versus execution time for both systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinstoids = dict()\n",
    "numjoins = dict()\n",
    "for parts in all_worq_results_adaptive:\n",
    "    id  = parts[0]\n",
    "    if id not in cold_ids:\n",
    "        if parts[5] in numjoins:\n",
    "            lst = numjoins[parts[5]]\n",
    "            lst.append(id)\n",
    "            numjoins[parts[5]]=lst\n",
    "        else:\n",
    "            lst = list()\n",
    "            lst.append(id)\n",
    "            numjoins[parts[5]] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average scores per join pattern in WORQ-Adaptive\n",
    "results_join_worq_adaptive = dict()\n",
    "for key,val in numjoins.iteritems():\n",
    "    numelems = float(len(val))\n",
    "    total = 0\n",
    "    for v in val:\n",
    "        total += float(results_worq_adaptive[v])\n",
    "    avg = total/numelems\n",
    "    results_join_worq_adaptive[key] = avg\n",
    "\n",
    "results_join_worq_adaptive_sorted = collections.OrderedDict(sorted(results_join_worq_adaptive.items()))\n",
    "\n",
    "# Calculate corresponding average for S2RDF\n",
    "results_join_s2rdf = dict()\n",
    "for key,val in numjoins.iteritems():\n",
    "    numelems = float(len(val))\n",
    "    total = 0\n",
    "    for v in val:\n",
    "        total += float(results_s2rdf[v])\n",
    "    avg = total/numelems\n",
    "    results_join_s2rdf[key] = avg\n",
    "    \n",
    "results_join_s2rdf_sorted = collections.OrderedDict(sorted(results_join_s2rdf.items()))\n",
    "\n",
    "numjoins_out = open(\"/home/amadkour/projects/worq/\"+results_dir+\"/numjoins.csv\",\"w\")\n",
    "numjoins_out.write(\"NumJoins\\tCARD\\tS2RDF\\n\")\n",
    "for a,b in zip(results_join_worq_adaptive_sorted,results_join_s2rdf_sorted):\n",
    "    numjoins_out.write(str(a)+\"\\t\"+str(results_join_worq_adaptive_sorted[a])+\"\\t\"+str(results_join_s2rdf_sorted[b])+\"\\n\")\n",
    "                       \n",
    "numjoins_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
